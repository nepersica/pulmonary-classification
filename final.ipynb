{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/ncp/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import glob\n",
    "\n",
    "import pydicom\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0.공기누출', '1.과다팽창', '2.무기폐', '3.신생아호흡곤란증후군', '4.폐렴', '5.흉막삼출', '6.정상']\n",
    "classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "num_class = len(class_names)\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = True\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_tensor(image, label, name):\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = torch.from_numpy(image)\n",
    "    \n",
    "    data = {'name':name, 'input': image, 'label': label}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, external = False):\n",
    "    if external:\n",
    "        mode = 'test'\n",
    "    else: \n",
    "        mode = 'train'\n",
    "                            \n",
    "    class_0 = glob.glob(f\"/home/ncp/workspace/data/{mode}/01.공기누출/*/*/metadata/*\")\n",
    "    class_1 = glob.glob(f\"/home/ncp/workspace/data/{mode}/02.과다팽창/*/*/metadata/*\")\n",
    "    class_2 = glob.glob(f\"/home/ncp/workspace/data/{mode}/03.무기폐/*/*/metadata/*\")\n",
    "    class_3 = glob.glob(f\"/home/ncp/workspace/data/{mode}/04.신생아호흡곤란증후군/*/*/metadata/*\")\n",
    "    class_4 = glob.glob(f\"/home/ncp/workspace/data/{mode}/05.폐렴/*/*/metadata/*\")\n",
    "    class_5 = glob.glob(f\"/home/ncp/workspace/data/{mode}/06.흉막삼출/*/*/metadata/*\")\n",
    "    class_6 = glob.glob(f\"/home/ncp/workspace/data/{mode}/09.정상/*/*/metadata/*\")\n",
    "        \n",
    "    dataset = class_0 + class_1 + class_2 + class_3 + class_4 + class_5 + class_6\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfantDataset(Dataset):\n",
    "    def __init__(self, root_dir='./data/test', transform=True, image_size=None, external=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform \n",
    "        self.external=external\n",
    "        self.dataset = load_data(self.root_dir, self.external)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        data = self.dataset[index]\n",
    "        image, label = self._load_dicom(os.path.join(self.root_dir, data))\n",
    "        image = self._preprocess_image(image)\n",
    "        image = image.astype('float32')\n",
    "        \n",
    "        # resize image\n",
    "        dim = (self.image_size, self.image_size)\n",
    "        image = cv.resize(image, dim, interpolation = cv.INTER_AREA)\n",
    "        \n",
    "        data = _to_tensor(image, label, data[:-5])\n",
    "        return data\n",
    "\n",
    "    def _preprocess_image(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "        clahe = cv.createCLAHE(clipLimit=80)\n",
    "        image = clahe.apply(image)\n",
    "        \n",
    "        image1 = image - np.min(image)\n",
    "        image = image1 / np.max(image1)\n",
    "        # np_image *= 255\n",
    "        \n",
    "        if not len(image.shape) == 3:\n",
    "            _image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "            _image[:,:,0] = image\n",
    "            _image[:,:,1] = image\n",
    "            _image[:,:,2] = image\n",
    "        else:\n",
    "            _image = image\n",
    "            \n",
    "        return _image\n",
    "    \n",
    "    def _load_dicom(self, path):\n",
    "        with open(path, 'r', encoding='UTF8') as f:\n",
    "            content = json.load(f)\n",
    "            file_name = content['identifier']\n",
    "            dicom_path = os.path.join(self.root_dir, content['mask_image']['org_dicom_file'][4:])\n",
    "\n",
    "            class_id = int(content['patient']['diagnosis'])\n",
    "            if class_id == 9:\n",
    "                class_id = 7\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        dcm = pydicom.dcmread(dicom_path)\n",
    "        image = dcm.pixel_array\n",
    "        \n",
    "        return image, class_id - 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(root_dir, external=False):\n",
    "    if external:# external data\n",
    "        dataset = InfantDataset(root_dir=root_dir, transform=False, image_size=image_size, external=True)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=1)  \n",
    "    else:      # external data\n",
    "        dataset = InfantDataset(root_dir=root_dir, transform=False, image_size=image_size)   \n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=1)  \n",
    "        \n",
    "    return dataset, loader\n",
    "\n",
    "# pytorch Dataloader\n",
    "external_test_dataset, external_test_loader = get_data(root_dir='./data/test', external = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_external = len(external_test_dataset) \n",
    "\n",
    "num_batch_external = np.ceil(num_data_external / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, mode='test'):\n",
    "    dict_model = torch.load(path)\n",
    "    print(\"Get saved weights successfully.\")\n",
    "    \n",
    "    return dict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import ttach as tta\n",
    "\n",
    "transforms = tta.Compose([           \n",
    "    tta.Multiply(factors=[0.7, 1]),\n",
    "\n",
    "])\n",
    "\n",
    "def compute_metrics(model, test_loader, plot_roc_curve = False, mode='val'):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    score_list   = torch.Tensor([]).to(device)\n",
    "    pred_list    = torch.Tensor([]).to(device).long()\n",
    "    target_list  = torch.Tensor([]).to(device).long()\n",
    "\n",
    "    tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "    \n",
    "    for iter_num, data in enumerate(test_loader):\n",
    "        \n",
    "        # Convert image data into single channel data\n",
    "        image, target = data['input'].to(device), data['label'].to(device)\n",
    "        \n",
    "        if mode == 'val' :\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "        elif mode == 'test':\n",
    "            output = tta_model(image)\n",
    "        \n",
    "        # Log loss\n",
    "        val_loss += criterion(output, target.long()).item()\n",
    "        # Calculate the number of correctly classified examples\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        pred_list    = torch.cat([pred_list, pred.squeeze()])\n",
    "        target_list  = torch.cat([target_list, target.squeeze()])\n",
    "        \n",
    "    \n",
    "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
    "                                                  target_names = class_names,\n",
    "                                                  output_dict= True)\n",
    "\n",
    "    # sensitivity is the recall of the positive class\n",
    "    sensitivity = 0\n",
    "    for name in class_names:\n",
    "        sensitivity += classification_metrics[f'{name}']['recall']\n",
    "        \n",
    "    # specificity is the recall of the negative class \n",
    "    specificity = 0\n",
    "    for name in class_names:\n",
    "        specificity += classification_metrics[f'{name}']['precision']\n",
    "        \n",
    "    # accuracy\n",
    "    accuracy = classification_metrics['accuracy']\n",
    "    \n",
    "    f1_score = 2 * (specificity * sensitivity) / (specificity + sensitivity)\n",
    "    \n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
    "    \n",
    "    # put together values\n",
    "    metrics_dict = {\"Accuracy\": accuracy * 100,\n",
    "                    \"Sensitivity\": (sensitivity * 100) / num_class,\n",
    "                    \"Specificity\": (specificity * 100) / num_class,\n",
    "                    \"F1 Score\": (f1_score * 100) / num_class,\n",
    "                    \"Validation Loss\": val_loss / len(test_loader),\n",
    "                    \"Confusion Matrix\": conf_matrix,\n",
    "                    \"pred_list\": pred_list.tolist(),\n",
    "                    \"target_list\": target_list.tolist(),}\n",
    "    \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting_by_3(alex_prediction, res18_prediction,res50_prediction):\n",
    "    final_prediction = list()\n",
    "    for idx, (alex, res18, res50) in enumerate(zip(alex_prediction, res18_prediction, res50_prediction)):\n",
    "        # Keep track of votes per class\n",
    "        zero = one = two = three = four = five = six = 0\n",
    "\n",
    "        # Loop over all models\n",
    "        image_predictions = [alex, res18, res50]\n",
    "        for img_prediction in image_predictions:\n",
    "            # Voting\n",
    "            if img_prediction == 0:\n",
    "                zero += 1\n",
    "            elif img_prediction == 1:\n",
    "                one += 1\n",
    "            elif img_prediction == 2:\n",
    "                two += 1\n",
    "            elif img_prediction == 3:\n",
    "                three += 1\n",
    "            elif img_prediction == 4:\n",
    "                four += 1\n",
    "            elif img_prediction == 5:\n",
    "                five += 1\n",
    "            elif img_prediction == 6:\n",
    "                six += 1\n",
    "                \n",
    "        # Find max vote\n",
    "        count_dict = {'공기누출': zero, '과다팽창': one, '무기폐': two, '신생아호흡곤란증후군': three,\n",
    "                      '폐렴': four, '흉막삼출': five, '정상': six}\n",
    "        \n",
    "        highest = max(count_dict.values())\n",
    "        max_values = [k for k, v in count_dict.items() if v == highest]\n",
    "        ensemble_prediction = []\n",
    "        for max_value in max_values:\n",
    "            if max_value == '공기누출':\n",
    "                ensemble_prediction.append(0)\n",
    "            elif max_value == '과다팽창':\n",
    "                ensemble_prediction.append(1)\n",
    "            elif max_value == '무기폐':\n",
    "                ensemble_prediction.append(2)\n",
    "            elif max_value == '신생아호흡곤란증후군':\n",
    "                ensemble_prediction.append(3)\n",
    "            elif max_value == '폐렴':\n",
    "                ensemble_prediction.append(4)\n",
    "            elif max_value == '흉막삼출':\n",
    "                ensemble_prediction.append(5)\n",
    "            elif max_value == '정상':\n",
    "                ensemble_prediction.append(6)\n",
    "\n",
    "        predict = ''\n",
    "        if len(ensemble_prediction) > 1:\n",
    "            predict = res50\n",
    "        else:\n",
    "            predict = ensemble_prediction[0]\n",
    "        \n",
    "        res50_prediction[idx] = predict\n",
    "        \n",
    "    return res50_prediction.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def compute_metrics_test(alex_model, res18_model, res50_model, test_loader):\n",
    "    \n",
    "    alex_model.eval()\n",
    "    res18_model.eval()\n",
    "    res50_model.eval()\n",
    "    \n",
    "    val_loss = [0, 0, 0]\n",
    "    val_correct = [0, 0, 0]\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    alex_pred_list    = torch.Tensor([]).to(device).long()\n",
    "    res18_pred_list    = torch.Tensor([]).to(device).long()\n",
    "    res50_pred_list    = torch.Tensor([]).to(device).long()\n",
    "    \n",
    "    target_list  = torch.Tensor([]).to(device).long()\n",
    "\n",
    "    for iter_num, data in enumerate(tqdm(test_loader), 1):\n",
    "        \n",
    "        # Convert image data into single channel data\n",
    "        image, target = data['input'].to(device), data['label'].to(device)\n",
    "        \n",
    "        # Compute the loss\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "            alex_output = alex_model(image)\n",
    "            end = time.time()\n",
    "            \n",
    "            start = time.time()\n",
    "            res18_output = res18_model(image)\n",
    "            end = time.time()\n",
    "            \n",
    "            start = time.time()\n",
    "            res50_output = res50_model(image)\n",
    "            end = time.time()\n",
    "        \n",
    "        # Log loss\n",
    "        val_loss[0] += criterion(alex_output, target.long()).item()\n",
    "        val_loss[1] += criterion(res18_output, target.long()).item()\n",
    "        val_loss[2] += criterion(res50_output, target.long()).item()\n",
    "        \n",
    "        # Calculate the number of correctly classified examples\n",
    "        alex_pred = alex_output.argmax(dim=1, keepdim=True)\n",
    "        val_correct[0] += alex_pred.eq(target.long().view_as(alex_pred)).sum().item()\n",
    "        res18_pred = res18_output.argmax(dim=1, keepdim=True)\n",
    "        val_correct[1] += res18_pred.eq(target.long().view_as(res18_pred)).sum().item()\n",
    "        res50_pred = res50_output.argmax(dim=1, keepdim=True)\n",
    "        val_correct[2] += res50_pred.eq(target.long().view_as(res50_pred)).sum().item()\n",
    "        \n",
    "        # Bookkeeping \n",
    "        alex_pred_list    = torch.cat([alex_pred_list, alex_pred.squeeze()])\n",
    "        res18_pred_list    = torch.cat([res18_pred_list, res18_pred.squeeze()])\n",
    "        res50_pred_list    = torch.cat([res50_pred_list, res50_pred.squeeze()])\n",
    "        \n",
    "        target_list  = torch.cat([target_list, target.squeeze()])\n",
    "    \n",
    "    pred_list = majority_voting_by_3(alex_pred_list, res18_pred_list, res50_pred_list)\n",
    "    \n",
    "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
    "                                                  target_names = class_names,\n",
    "                                                  output_dict= True)\n",
    "\n",
    "    # sensitivity is the recall of the positive class\n",
    "    sensitivity = 0\n",
    "    for name in class_names:\n",
    "        sensitivity += classification_metrics[f'{name}']['recall']\n",
    "    \n",
    "    # specificity is the recall of the negative class \n",
    "    specificity = 0\n",
    "    for name in class_names:\n",
    "        specificity += classification_metrics[f'{name}']['recall']\n",
    "    \n",
    "    f1_score = 2 * (specificity * sensitivity) / (specificity + sensitivity)\n",
    "    # accuracy\n",
    "    accuracy = classification_metrics['accuracy']\n",
    "    \n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    \n",
    "    # put together values\n",
    "    metrics_dict = {\"Accuracy\": accuracy,\n",
    "                    \"Sensitivity\": (sensitivity * 100) / num_class,\n",
    "                    \"Specificity\": (specificity * 100) / num_class,\n",
    "                    \"F1 Score\": (f1_score * 100) / num_class,\n",
    "                    \"Confusion Matrix\": conf_matrix,\n",
    "                    \"Validation Loss\": val_loss / len(test_loader),\n",
    "                    \"pred_list\": pred_list.tolist(),\n",
    "                    \"target_list\": target_list.tolist(),}\n",
    "    \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_model = load_model('/home/ncp/workspace/seung-ah/checkpoint/best/best_model-alex.pt')\n",
    "res18_model = load_model('/home/ncp/workspace/seung-ah/checkpoint/best/best_model-res18.pt')\n",
    "res50_model = load_model('/home/ncp/workspace/seung-ah/checkpoint/best/best_model-resnet50(v1).pt')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "metrics_dict = compute_metrics_test(alex_model, res18_model, res50_model, external_test_loader)\n",
    "print('------------------- Test Performance --------------------------------------')\n",
    "print(\"Accuracy \\t {:.3f}\".format(metrics_dict['Accuracy']))\n",
    "print(\"Sensitivity \\t {:.3f}\".format(metrics_dict['Sensitivity']))\n",
    "print(\"Specificity \\t {:.3f}\".format(metrics_dict['Specificity']))\n",
    "print(\"F1 Score \\t {:.3f}\".format(metrics_dict['F1 Score']))\n",
    "print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
