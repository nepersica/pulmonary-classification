{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "import pydicom\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0.공기누출', '1.과다팽창', '2.무기폐', '3.신생아호흡곤란증후군', '4.폐렴', '5.흉막삼출', '6.정상']\n",
    "classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "num_class = len(class_names)\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = True\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_augment(image):\n",
    "    transform = A.Compose([\n",
    "                        A.HorizontalFlip(p=0.3),\n",
    "                        A.VerticalFlip(p=0.3),\n",
    "#                         A.InvertImg(p=0.1),\n",
    "                        A.ShiftScaleRotate(shift_limit=(-0.05, 0.05), rotate_limit=(-10, 10), scale_limit=(0, 0.05), border_mode=cv.BORDER_CONSTANT, value=0, p=0.5),\n",
    "                        A.RandomBrightnessContrast(brightness_limit=(0, 0.3), contrast_limit=(0, 0.3), p=0.3),\n",
    "                        A.GaussianBlur(blur_limit=(7, 15), p=0.3),  \n",
    "                        A.OpticalDistortion(distort_limit=0.1, shift_limit=0.1, border_mode=cv.BORDER_CONSTANT, value=0, p=0.3),\n",
    "                        ])\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "\n",
    "    image = augmented['image']\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def _to_tensor(image, label, name):\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = torch.from_numpy(image)\n",
    "    \n",
    "    data = {'name':name, 'input': image, 'label': label}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfantDataset(Dataset):\n",
    "    def __init__(self, root_dir='/home/ncp/workspace/seung-ah/hdf5', transform=True, image_size=None, mode='train'):\n",
    "        self.root_dir = os.path.join(root_dir, mode)\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "        self.mode=mode        \n",
    "        self.dataset = os.listdir(self.root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):            \n",
    "        data = self.dataset[index]\n",
    "        image, label = self._load_hdf5(os.path.join(self.root_dir, data))\n",
    "        image = self._preprocess_image(image)\n",
    "        image = image.astype('float32')\n",
    "        \n",
    "        # agumentation\n",
    "        if self.transform :\n",
    "            image = _random_augment(image)\n",
    "            \n",
    "        # resize image\n",
    "        dim = (self.image_size, self.image_size)\n",
    "        image = cv.resize(image, dim, interpolation = cv.INTER_AREA)\n",
    "\n",
    "        data = _to_tensor(image, label, data[:-5])\n",
    "        return data\n",
    "\n",
    "    def _preprocess_image(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "        clahe = cv.createCLAHE(clipLimit=80)\n",
    "        image = clahe.apply(image)\n",
    "        \n",
    "        image1 = image - np.min(image)\n",
    "        image = image1 / np.max(image1)\n",
    "        # np_image *= 255\n",
    "        \n",
    "        if not len(image.shape) == 3:\n",
    "            _image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "            _image[:,:,0] = image\n",
    "            _image[:,:,1] = image\n",
    "            _image[:,:,2] = image\n",
    "        else:\n",
    "            _image = image\n",
    "            \n",
    "        return _image\n",
    "    \n",
    "    def _load_hdf5(self, hdf5_path):\n",
    "        with h5py.File(hdf5_path, 'r') as hf:  # open a hdf5 file\n",
    "            keys = list(hf.keys())\n",
    "            keys.sort()                   # sort key(image, input)\n",
    "\n",
    "            for fName in keys:\n",
    "                context = hf[fName]\n",
    "\n",
    "                if fName == 'input':\n",
    "                    image = np.array(hf.get(context.name))\n",
    "                elif fName == 'class_id':\n",
    "                    class_id = np.array(hf.get(context.name))[0]-1\n",
    "                    \n",
    "        hf.close()\n",
    "        \n",
    "        return image, class_id\n",
    "                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mode):\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = InfantDataset(transform=True, image_size=image_size, mode=mode)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1) \n",
    "    elif mode == 'val' or mode == 'test' :\n",
    "        dataset = InfantDataset(transform=False, image_size=image_size, mode=mode)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=1) \n",
    "\n",
    "    return dataset, loader\n",
    "\n",
    "# pytorch Dataloader\n",
    "train_dataset, train_loader = get_data('train')\n",
    "val_dataset, val_loader = get_data('val')\n",
    "test_dataset, test_loader = get_data('test')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_train = len(train_dataset) \n",
    "num_data_val = len(val_dataset)  \n",
    "num_data_test = len(test_dataset)  \n",
    "\n",
    "num_batch_train = np.ceil(num_data_train / batch_size) \n",
    "num_batch_val = np.ceil(num_data_val / batch_size)\n",
    "num_batch_test = np.ceil(num_data_test / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_model = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "res18_model = torchvision.models.resnet18(pretrained=True).to(device)\n",
    "res50_model = torchvision.models.resnet50(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = alex_model.classifier[6].in_features\n",
    "fc = nn.Sequential(OrderedDict([\n",
    "                                ('fc1', nn.Linear(num_ftrs,100)),\n",
    "                                ('relu', nn.ReLU()),\n",
    "                                ('drop-out', nn.Dropout(p=0.2, inplace=True)),\n",
    "                                ('fc2', nn.Linear(100, num_class)),  # 3 is the number of classes we have in the dataset\n",
    "                            ]))\n",
    "alex_model.classifier[6] = fc.to(device)\n",
    "\n",
    "\n",
    "num_ftrs = res18_model.fc.in_features\n",
    "fc = nn.Sequential(OrderedDict([\n",
    "                                ('fc1', nn.Linear(num_ftrs,100)),\n",
    "                                ('relu', nn.ReLU()),\n",
    "                                ('drop-out', nn.Dropout(p=0.2, inplace=True)),\n",
    "                                ('fc2', nn.Linear(100, num_class)),  # 3 is the number of classes we have in the dataset\n",
    "                            ]))\n",
    "res18_model.fc = fc.to(device)\n",
    "\n",
    "\n",
    "num_ftrs = res50_model.fc.in_features\n",
    "fc = nn.Sequential(OrderedDict([\n",
    "                                ('fc1', nn.Linear(num_ftrs,100)),\n",
    "                                ('relu', nn.ReLU()),\n",
    "                                ('drop-out', nn.Dropout(p=0.2, inplace=True)),\n",
    "                                ('fc2', nn.Linear(100, num_class)),  # 3 is the number of classes we have in the dataset\n",
    "                            ]))\n",
    "res50_model.fc = fc.to(device)\n",
    "# model[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(alex_model.parameters()).is_cuda # returns a boolean\n",
    "next(res18_model.parameters()).is_cuda # returns a boolean\n",
    "next(res50_model.parameters()).is_cuda # returns a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr=1e-5\n",
    "momentum = 0.9\n",
    "num_epoch=200\n",
    "\n",
    "train_continue = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.fc.parameters(), lr= lr, momentum= momentum)  \n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum= momentum)  \n",
    "\n",
    "alex_optimizer = optim.Adam(alex_model.parameters(), lr= lr)  \n",
    "res18_optimizer = optim.Adam(res18_model.parameters(), lr= lr)  \n",
    "res50_optimizer = optim.Adam(res50_model.parameters(), lr= lr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, mode='test'):\n",
    "    dict_model = torch.load(path)\n",
    "    print(\"Get saved weights successfully.\")\n",
    "    if mode == 'test':\n",
    "        return load_model\n",
    "    else:\n",
    "        epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
    "        return model, epoch\n",
    "\n",
    "def save_model(ckpt_dir, model, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    if 'best' in ckpt_dir:\n",
    "        torch.save({'model': model.state_dict(), 'optim': optim.state_dict()},\n",
    "            \"./%s/model_best.pth\" % (ckpt_dir))\n",
    "        print(f'>> save model_best.pth')\n",
    "    else:\n",
    "        torch.save({'model': model.state_dict(), 'optim': optim.state_dict()},\n",
    "                    \"./%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n",
    "        print(f'>> save model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "def compute_metrics(model, test_loader, plot_roc_curve = False, mode='val'):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    score_list   = torch.Tensor([]).to(device)\n",
    "    pred_list    = torch.Tensor([]).to(device).long()\n",
    "    target_list  = torch.Tensor([]).to(device).long()\n",
    "    for iter_num, data in enumerate(test_loader):\n",
    "        \n",
    "        # Convert image data into single channel data\n",
    "        image, target = data['input'].to(device), data['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "        # Log loss\n",
    "        val_loss += criterion(output, target.long()).item()\n",
    "        # Calculate the number of correctly classified examples\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        pred_list    = torch.cat([pred_list, pred.squeeze()])\n",
    "        target_list  = torch.cat([target_list, target.squeeze()])\n",
    "        \n",
    "    \n",
    "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
    "                                                  target_names = class_names,\n",
    "                                                  output_dict= True)\n",
    "\n",
    "    # sensitivity is the recall of the positive class\n",
    "    sensitivity = 0\n",
    "    for name in class_names:\n",
    "        sensitivity += classification_metrics[f'{name}']['recall']\n",
    "        \n",
    "    # specificity is the recall of the negative class \n",
    "    specificity = 0\n",
    "    for name in class_names:\n",
    "        specificity += classification_metrics[f'{name}']['precision']\n",
    "        \n",
    "    # accuracy\n",
    "    accuracy = classification_metrics['accuracy']\n",
    "    \n",
    "    \n",
    "    f1_score = 2 * (specificity * sensitivity) / (specificity + sensitivity)\n",
    "    \n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
    "    \n",
    "    # put together values\n",
    "    metrics_dict = {\"Accuracy\": accuracy * 100,\n",
    "                    \"Sensitivity\": (sensitivity * 100) / num_class,\n",
    "                    \"Specificity\": (specificity * 100) / num_class,\n",
    "                    \"F1 Score\": (f1_score * 100) / num_class,\n",
    "                    \"Validation Loss\": val_loss / len(test_loader),\n",
    "                    \"Confusion Matrix\": conf_matrix,\n",
    "                    \"pred_list\": pred_list.tolist(),\n",
    "                    \"target_list\": target_list.tolist(),}\n",
    "    \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience = 8):\n",
    "        super(EarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.previous_loss = int(1e8)\n",
    "        self.previous_accuracy = 0\n",
    "        self.init = False\n",
    "        self.accuracy_decrease_iters = 0\n",
    "        self.loss_increase_iters = 0\n",
    "        self.best_running_accuracy = 0\n",
    "        self.best_running_loss = int(1e7)\n",
    "    \n",
    "    def add_data(self, model, loss, accuracy):\n",
    "        \n",
    "        # compute moving average\n",
    "        if not self.init:\n",
    "            running_loss = loss\n",
    "            running_accuracy = accuracy \n",
    "            self.init = True\n",
    "        \n",
    "        else:\n",
    "            running_loss = 0.2 * loss + 0.8 * self.previous_loss\n",
    "            running_accuracy = 0.2 * accuracy + 0.8 * self.previous_accuracy\n",
    "        \n",
    "        # check if running accuracy has improved beyond the best running accuracy recorded so far\n",
    "        if running_accuracy < self.best_running_accuracy:\n",
    "            self.accuracy_decrease_iters += 1\n",
    "        else:\n",
    "            self.best_running_accuracy = running_accuracy\n",
    "            self.accuracy_decrease_iters = 0\n",
    "        \n",
    "        # check if the running loss has decreased from the best running loss recorded so far\n",
    "        if running_loss > self.best_running_loss:\n",
    "            self.loss_increase_iters += 1\n",
    "        else:\n",
    "            self.best_running_loss = running_loss\n",
    "            self.loss_increase_iters = 0\n",
    "        \n",
    "        # log the current accuracy and loss\n",
    "        self.previous_accuracy = running_accuracy\n",
    "        self.previous_loss = running_loss        \n",
    "        \n",
    "    \n",
    "    def stop(self):\n",
    "        \n",
    "        # compute thresholds\n",
    "        accuracy_threshold = self.accuracy_decrease_iters > self.patience\n",
    "        loss_threshold = self.loss_increase_iters > self.patience\n",
    "        \n",
    "        \n",
    "        # return codes corresponding to exhuaustion of patience for either accuracy or loss \n",
    "        # or both of them\n",
    "        if accuracy_threshold and loss_threshold:\n",
    "            return 1\n",
    "        \n",
    "        if accuracy_threshold:\n",
    "            return 2\n",
    "        \n",
    "        if loss_threshold:\n",
    "            return 3\n",
    "        \n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def reset(self):\n",
    "        # reset\n",
    "        self.accuracy_decrease_iters = 0\n",
    "        self.loss_increase_iters = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, mode):\n",
    "    early_stopper = EarlyStopping(patience = 8)\n",
    "    lr = 1e-5\n",
    "    print(f'pulmonary-classification-{mode}')\n",
    "    \n",
    "    if mode == 'alex':\n",
    "        optimizer = alex_optimizer\n",
    "    elif mode == 'res18':\n",
    "        optimizer = res18_optimizer\n",
    "    elif mode == 'res50':\n",
    "        optimizer = res50_optimizer\n",
    "\n",
    "    best_model = model\n",
    "    best_val_score = 0\n",
    "    \n",
    "    st_epoch = 0\n",
    "    \n",
    "    for epoch in range(st_epoch + 1, num_epoch + 1):\n",
    "\n",
    "        model.train()    \n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for iter_num, data in enumerate(tqdm(train_loader), 1):\n",
    "            image = data['input'].to(device)       # [N, 3, image_size, image_size]\n",
    "            target = data['label'].to(device)        # [N, image_size, image_size]\n",
    "\n",
    "            # Compute the loss\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target.long())\n",
    "\n",
    "            # Log loss\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Calculate the number of correctly classified examples\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "\n",
    "        # Compute and print the performance metrics\n",
    "        metrics_dict = compute_metrics(model, val_loader)\n",
    "\n",
    "        # Save the model with best validation accuracy\n",
    "        if metrics_dict['F1 Score'] > best_val_score:\n",
    "            torch.save(model, f\"./checkpoint/best/best_model-{mode}.pt\")\n",
    "            best_val_score = metrics_dict['F1 Score']\n",
    "            print('Save best model...')\n",
    "\n",
    "        # print the metrics for training data for the epoch\n",
    "        print('Training Performance Epoch {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "            epoch, train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "            100.0 * train_correct / len(train_loader.dataset)))\n",
    "        epoch_loss = train_loss/len(train_loader.dataset)\n",
    "        epoch_acc = 100.0 * train_correct / len(train_loader.dataset)\n",
    "        wandb.log({\"train-loss\": epoch_loss, \"train-acc\": epoch_acc, })\n",
    "\n",
    "        print(f\"Validation Performance Epoch: {epoch}, Loss: {metrics_dict['Validation Loss']}, Accuracy: {metrics_dict['Accuracy']}, F1 Score: {metrics_dict['F1 Score']}\")\n",
    "\n",
    "        wandb.log({\"val-loss\": metrics_dict[\"Validation Loss\"],\n",
    "                   \"val-acc\": metrics_dict[\"Accuracy\"],\n",
    "                   \"val-sensitivity\": metrics_dict[\"Sensitivity\"],\n",
    "                   \"val-specificity\": metrics_dict[\"Specificity\"],\n",
    "                   \"val_f1-score\": metrics_dict[\"F1 Score\"],\n",
    "                  })\n",
    "\n",
    "        \n",
    "        # Add data to the EarlyStopper object\n",
    "        early_stopper.add_data(model, metrics_dict['Validation Loss'], metrics_dict['F1 Score'])\n",
    "\n",
    "        # If both accuracy and loss are not improving, stop the training\n",
    "        if early_stopper.stop() == 1:\n",
    "            break\n",
    "\n",
    "        # if only loss is not improving, lower the learning rate\n",
    "        if early_stopper.stop() == 3:\n",
    "            \n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr *= 0.1\n",
    "                param_group['lr'] = lr\n",
    "                print('Updating the learning rate to {}'.format(lr))\n",
    "                early_stopper.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('################################# Training AlexNet #################################')\n",
    "training(alex_model, \"alex\")\n",
    "print('################################# Training ResNet18 #################################')\n",
    "training(res18_model, \"res18\")\n",
    "print('################################# Training ResNet50 #################################')\n",
    "training(res50_model, \"res50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting_by_3(alex_prediction, res18_prediction,res50_prediction):\n",
    "    final_prediction = list()\n",
    "    for idx, (alex, res18, res50) in enumerate(zip(alex_prediction, res18_prediction, res50_prediction)):\n",
    "        # Keep track of votes per class\n",
    "        zero = one = two = three = four = five = six = 0\n",
    "\n",
    "        # Loop over all models\n",
    "        image_predictions = [alex, res18, res50]\n",
    "        for img_prediction in image_predictions:\n",
    "            # Voting\n",
    "            if img_prediction == 0:\n",
    "                zero += 1\n",
    "            elif img_prediction == 1:\n",
    "                one += 1\n",
    "            elif img_prediction == 2:\n",
    "                two += 1\n",
    "            elif img_prediction == 3:\n",
    "                three += 1\n",
    "            elif img_prediction == 4:\n",
    "                four += 1\n",
    "            elif img_prediction == 5:\n",
    "                five += 1\n",
    "            elif img_prediction == 6:\n",
    "                six += 1\n",
    "                \n",
    "        # Find max vote\n",
    "        count_dict = {'공기누출': zero, '과다팽창': one, '무기폐': two, '신생아호흡곤란증후군': three,\n",
    "                      '폐렴': four, '흉막삼출': five, '정상': six}\n",
    "        \n",
    "        highest = max(count_dict.values())\n",
    "        max_values = [k for k, v in count_dict.items() if v == highest]\n",
    "        ensemble_prediction = []\n",
    "        for max_value in max_values:\n",
    "            if max_value == '공기누출':\n",
    "                ensemble_prediction.append(0)\n",
    "            elif max_value == '과다팽창':\n",
    "                ensemble_prediction.append(1)\n",
    "            elif max_value == '무기폐':\n",
    "                ensemble_prediction.append(2)\n",
    "            elif max_value == '신생아호흡곤란증후군':\n",
    "                ensemble_prediction.append(3)\n",
    "            elif max_value == '폐렴':\n",
    "                ensemble_prediction.append(4)\n",
    "            elif max_value == '흉막삼출':\n",
    "                ensemble_prediction.append(5)\n",
    "            elif max_value == '정상':\n",
    "                ensemble_prediction.append(6)\n",
    "\n",
    "        predict = ''\n",
    "        if len(ensemble_prediction) > 1:\n",
    "            predict = res50\n",
    "        else:\n",
    "            predict = ensemble_prediction[0]\n",
    "        \n",
    "        res50_prediction[idx] = predict\n",
    "        \n",
    "    return res50_prediction.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def compute_metrics_test(alex_model, res18_model, res50_model, test_loader):\n",
    "    \n",
    "    alex_model.eval()\n",
    "    res18_model.eval()\n",
    "    res50_model.eval()\n",
    "    \n",
    "    val_loss = [0, 0, 0]\n",
    "    val_correct = [0, 0, 0]\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    alex_pred_list    = torch.Tensor([]).to(device).long()\n",
    "    res18_pred_list    = torch.Tensor([]).to(device).long()\n",
    "    res50_pred_list    = torch.Tensor([]).to(device).long()\n",
    "    \n",
    "    target_list  = torch.Tensor([]).to(device).long()\n",
    "\n",
    "    \n",
    "    for iter_num, data in enumerate(test_loader):\n",
    "        \n",
    "        # Convert image data into single channel data\n",
    "        image, target = data['input'].to(device), data['label'].to(device)\n",
    "        \n",
    "        # Compute the loss\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "            alex_output = alex_model(image)\n",
    "            end = time.time()\n",
    "            \n",
    "            start = time.time()\n",
    "            res18_output = res18_model(image)\n",
    "            end = time.time()\n",
    "            \n",
    "            start = time.time()\n",
    "            res50_output = res50_model(image)\n",
    "            end = time.time()\n",
    "        \n",
    "        # Log loss\n",
    "        val_loss[0] += criterion(alex_output, target.long()).item()\n",
    "        val_loss[1] += criterion(res18_output, target.long()).item()\n",
    "        val_loss[2] += criterion(res50_output, target.long()).item()\n",
    "        \n",
    "        # Calculate the number of correctly classified examples\n",
    "        alex_pred = alex_output.argmax(dim=1, keepdim=True)\n",
    "        val_correct[0] += alex_pred.eq(target.long().view_as(alex_pred)).sum().item()\n",
    "        res18_pred = res18_output.argmax(dim=1, keepdim=True)\n",
    "        val_correct[1] += res18_pred.eq(target.long().view_as(res18_pred)).sum().item()\n",
    "        res50_pred = res50_output.argmax(dim=1, keepdim=True)\n",
    "        val_correct[2] += res50_pred.eq(target.long().view_as(res50_pred)).sum().item()\n",
    "        \n",
    "        # Bookkeeping \n",
    "        alex_pred_list    = torch.cat([alex_pred_list, alex_pred.squeeze()])\n",
    "        res18_pred_list    = torch.cat([res18_pred_list, res18_pred.squeeze()])\n",
    "        res50_pred_list    = torch.cat([res50_pred_list, res50_pred.squeeze()])\n",
    "        \n",
    "        target_list  = torch.cat([target_list, target.squeeze()])\n",
    "    \n",
    "    pred_list = majority_voting_by_3(alex_pred_list, res18_pred_list, res50_pred_list)\n",
    "    \n",
    "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
    "                                                  target_names = class_names,\n",
    "                                                  output_dict= True)\n",
    "\n",
    "    # sensitivity is the recall of the positive class\n",
    "    sensitivity = 0\n",
    "    for name in class_names:\n",
    "        sensitivity += classification_metrics[f'{name}']['recall']\n",
    "    \n",
    "    # specificity is the recall of the negative class \n",
    "    specificity = 0\n",
    "    for name in class_names:\n",
    "        specificity += classification_metrics[f'{name}']['recall']\n",
    "    \n",
    "    f1_score = 2 * (specificity * sensitivity) / (specificity + sensitivity)\n",
    "    # accuracy\n",
    "    accuracy = classification_metrics['accuracy']\n",
    "    \n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    \n",
    "    # put together values\n",
    "    metrics_dict = {\"Accuracy\": accuracy,\n",
    "                    \"Sensitivity\": (sensitivity * 100) / num_class,\n",
    "                    \"Specificity\": (specificity * 100) / num_class,\n",
    "                    \"F1 Score\": (f1_score * 100) / num_class,\n",
    "                    \"Confusion Matrix\": conf_matrix,\n",
    "                    \"Validation Loss\": val_loss / len(test_loader),\n",
    "                    \"pred_list\": pred_list.tolist(),\n",
    "                    \"target_list\": target_list.tolist(),}\n",
    "    \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_model = load_model('./checkpoint/best/best_model-alex.pt')\n",
    "res18_model = load_model('./checkpoint/best/best_model-res18.pt')\n",
    "res50_model = load_model('./checkpoint/best/best_model-resnet50.pt')\n",
    "    \n",
    "metrics_dict = compute_metrics_test(alex_model, res18_model, res50_model, test_loader)\n",
    "print('------------------- Test Performance --------------------------------------')\n",
    "print(\"Accuracy \\t {:.3f}\".format(metrics_dict['Accuracy']))\n",
    "print(\"Sensitivity \\t {:.3f}\".format(metrics_dict['Sensitivity']))\n",
    "print(\"Specificity \\t {:.3f}\".format(metrics_dict['Specificity']))\n",
    "print(\"Specificity \\t {:.3f}\".format(metrics_dict['F1 Score']))\n",
    "print(\"---------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
