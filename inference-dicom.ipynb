{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "import pydicom\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0.공기누출', '1.과다팽창', '2.무기폐', '3.신생아호흡곤란증후군', '4.폐렴', '5.흉막삼출', '6.정상']\n",
    "classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "num_class = len(class_names)\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = False\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_tensor(image, label, name):\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1]))\n",
    "        \n",
    "    data = {'name':name, 'input': image, 'label': label}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfantDataset(Dataset):\n",
    "    def __init__(self, root_dir='/home/ncp/workspace/data/', transform=True, image_size=None, mode='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.root_dir = os.path.join(root_dir, mode)\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "        self.mode=mode        \n",
    "\n",
    "        self.dataset = open(f\"/home/ncp/workspace/seung-ah/{self.mode}.txt\",'r').read().splitlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):            \n",
    "        data = self.dataset[index]\n",
    "        image, label = self._load_dicom(os.path.join(self.root_dir, data))\n",
    "        image = self._preprocess_image(image)\n",
    "        \n",
    "        data = _to_tensor(image, label, data[:-5])\n",
    "        return data\n",
    "\n",
    "    def _preprocess_image(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "        clahe = cv.createCLAHE(clipLimit=20)\n",
    "        image = clahe.apply(image)\n",
    "        \n",
    "        image1 = image - np.min(image)\n",
    "        image = image1 / np.max(image1)\n",
    "        \n",
    "        # agumentation\n",
    "        if self.transform :\n",
    "            image = _random_augment(image*255)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def _load_dicom(self, image_path):\n",
    "        with open(image_path, 'r', encoding='UTF8') as f:\n",
    "            content = json.load(f)\n",
    "        name = content['identifier']\n",
    "        dicom_path = os.path.join(self.root_dir, content['mask_image']['org_dicom_file'][4:])\n",
    "        f.close()\n",
    "        \n",
    "        dcm = pydicom.dcmread(dicom_path)\n",
    "        origin_image = dcm.pixel_array\n",
    "        \n",
    "        class_id = int(content['patient']['diagnosis'])\n",
    "        if class_id == 9:\n",
    "            class_id = 7\n",
    "        \n",
    "        return origin_image, class_id-1\n",
    "                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mode):\n",
    "    dataset = InfantDataset(transform=False, image_size=image_size, mode=mode)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=1) \n",
    "\n",
    "    return dataset, loader\n",
    "\n",
    "# pytorch Dataloader\n",
    "test_dataset, test_loader = get_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_test = len(test_dataset)  \n",
    "\n",
    "num_batch_test = np.ceil(num_data_test / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    dict_model = torch.load(path)\n",
    "    print(\"Get saved weights successfully.\")\n",
    "    \n",
    "    return dict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "transforms = tta.Compose([           \n",
    "    tta.Multiply(factors=[0.7, 1]),\n",
    "\n",
    "])\n",
    "\n",
    "def compute_metrics(model, test_loader, plot_roc_curve = False, mode='val'):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    losses = []\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    score_list   = torch.Tensor([]).to(device)\n",
    "    pred_list    = torch.Tensor([]).to(device).long()\n",
    "    target_list  = torch.Tensor([]).to(device).long()\n",
    "\n",
    "    for iter_num, data in enumerate(test_loader):\n",
    "        \n",
    "        # Convert image data into single channel data\n",
    "        image, target = data['input'].to(device), data['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "        losses.append({'name': data[\"name\"], 'loss': criterion(output, target.long()).item()})\n",
    "        \n",
    "        # Log loss\n",
    "        val_loss += criterion(output, target.long()).item()\n",
    "        # Calculate the number of correctly classified examples\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        pred_list    = torch.cat([pred_list, pred.squeeze()])\n",
    "        target_list  = torch.cat([target_list, target.squeeze()])\n",
    "        \n",
    "    \n",
    "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
    "                                                  target_names = class_names,\n",
    "                                                  output_dict= True)\n",
    "\n",
    "    # sensitivity is the recall of the positive class\n",
    "    sensitivity = 0\n",
    "    for name in class_names:\n",
    "        sensitivity += classification_metrics[f'{name}']['recall']\n",
    "        \n",
    "    # specificity is the recall of the negative class \n",
    "    specificity = 0\n",
    "    for name in class_names:\n",
    "        specificity += classification_metrics[f'{name}']['precision']\n",
    "        \n",
    "    # accuracy\n",
    "    accuracy = classification_metrics['accuracy']\n",
    "    \n",
    "    \n",
    "    f1_score = 2 * (specificity * sensitivity) / (specificity + sensitivity)\n",
    "    \n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
    "    \n",
    "    # put together values\n",
    "    metrics_dict = {\"Accuracy\": accuracy * 100,\n",
    "                    \"Sensitivity\": (sensitivity * 100) / num_class,\n",
    "                    \"Specificity\": (specificity * 100) / num_class,\n",
    "                    \"F1 Score\": (f1_score * 100) / num_class,\n",
    "                    \"Validation Loss\": val_loss / len(test_loader),\n",
    "                    \"Confusion Matrix\": conf_matrix,\n",
    "                    \"pred_list\": pred_list.tolist(),\n",
    "                    \"target_list\": target_list.tolist(),}\n",
    "    \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import ttach as tta\n",
    "\n",
    "transforms = tta.Compose([           \n",
    "    tta.Multiply(factors=[0.7, 1]),\n",
    "\n",
    "])\n",
    "\n",
    "def compute_metrics(model, test_loader, plot_roc_curve = False, mode='val'):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    losses = []\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    score_list   = torch.Tensor([]).to(device)\n",
    "    pred_list    = torch.Tensor([]).to(device).long()\n",
    "    target_list  = torch.Tensor([]).to(device).long()\n",
    "\n",
    "    tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "    \n",
    "    for iter_num, data in enumerate(test_loader):\n",
    "        \n",
    "        # Convert image data into single channel data\n",
    "        image, target = data['input'].to(device), data['label'].to(device)\n",
    "        \n",
    "        if mode == 'val' :\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "        elif mode == 'test':\n",
    "            output = tta_model(image)\n",
    "        \n",
    "        losses.append({'name': data[\"name\"], 'loss': criterion(output, target.long()).item()})\n",
    "        \n",
    "        # Log loss\n",
    "        val_loss += criterion(output, target.long()).item()\n",
    "        # Calculate the number of correctly classified examples\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        pred_list    = torch.cat([pred_list, pred.squeeze()])\n",
    "        target_list  = torch.cat([target_list, target.squeeze()])\n",
    "        \n",
    "    \n",
    "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
    "                                                  target_names = class_names,\n",
    "                                                  output_dict= True)\n",
    "\n",
    "    # sensitivity is the recall of the positive class\n",
    "    sensitivity = 0\n",
    "    for name in class_names:\n",
    "        sensitivity += classification_metrics[f'{name}']['recall']\n",
    "        \n",
    "    # specificity is the recall of the negative class \n",
    "    specificity = 0\n",
    "    for name in class_names:\n",
    "        specificity += classification_metrics[f'{name}']['precision']\n",
    "        \n",
    "    # accuracy\n",
    "    accuracy = classification_metrics['accuracy']\n",
    "    \n",
    "    \n",
    "    f1_score = 2 * (specificity * sensitivity) / (specificity + sensitivity)\n",
    "    \n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
    "    \n",
    "    # put together values\n",
    "    metrics_dict = {\"Accuracy\": accuracy * 100,\n",
    "                    \"Sensitivity\": (sensitivity * 100) / num_class,\n",
    "                    \"Specificity\": (specificity * 100) / num_class,\n",
    "                    \"F1 Score\": (f1_score * 100) / num_class,\n",
    "                    \"Validation Loss\": val_loss / len(test_loader),\n",
    "                    \"Confusion Matrix\": conf_matrix,\n",
    "                    \"pred_list\": pred_list.tolist(),\n",
    "                    \"target_list\": target_list.tolist(),}\n",
    "    \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet50'\n",
    "model = load_model(f'./checkpoint/best/best_model-{model_name}.pt')\n",
    "# print(model)\n",
    "\n",
    "lr=1e-5\n",
    "momentum = 0.9\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "metrics_dict = compute_metrics(model, test_loader, mode='test')\n",
    "print('------------------- Test Performance --------------------------------------')\n",
    "print(\"Accuracy \\t {:.3f}\".format(metrics_dict['Accuracy']))\n",
    "print(\"Sensitivity \\t {:.3f}\".format(metrics_dict['Sensitivity']))\n",
    "print(\"Specificity \\t {:.3f}\".format(metrics_dict['Specificity']))\n",
    "print(\"F1 Score \\t {:.3f}\".format(metrics_dict['F1 Score']))\n",
    "print(\"---------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
