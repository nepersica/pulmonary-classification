{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "import pydicom\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0.공기누출', '1.과다팽창', '2.무기폐', '3.신생아호흡곤란증후군', '4.폐렴', '5.흉막삼출', '6.정상']\n",
    "classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "num_class = len(class_names)\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = True\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_augment(image):\n",
    "    transform = A.Compose([\n",
    "                        A.HorizontalFlip(p=0.3),\n",
    "                        A.HorizontalFlip(p=0.05),\n",
    "                        A.OneOf([\n",
    "                                    A.InvertImg(p=0.5),\n",
    "                                    A.ShiftScaleRotate(shift_limit=(0, 0), rotate_limit=(-5, 5), scale_limit=(-0.15,0.05), border_mode=cv.BORDER_CONSTANT, value=0, p=0.3),\n",
    "                                    A.OpticalDistortion(distort_limit=0.1, shift_limit=0, border_mode=cv.BORDER_CONSTANT, value=0, p=0.3),\n",
    "                                ]),\n",
    "#       \n",
    "                        A.Resize(image_size, image_size),                  \n",
    "                        A.lize(mean=0.5, std=0.5)\n",
    "                    ])\n",
    "\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "\n",
    "    image = augmented['image']\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def _to_tensor(image, label, name):\n",
    "    \n",
    "#     image = np.transpose(image, (2, 0, 1))\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1]))\n",
    "    \n",
    "    data = {'name':name, 'input': image, 'label': label}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfantDataset(Dataset):\n",
    "    def __init__(self, root_dir='/home/ncp/workspace/seung-ah/hdf5', transform=True, image_size=None, mode='train'):\n",
    "        self.root_dir = os.path.join(root_dir, mode)\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "        self.mode=mode        \n",
    "        self.dataset = os.listdir(self.root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):            \n",
    "        data = self.dataset[index]\n",
    "        image, label = self._load_hdf5(os.path.join(self.root_dir, data))\n",
    "        image = self._preprocess_image(image)\n",
    "        \n",
    "        data = _to_tensor(image, label, data[:-5])\n",
    "        return data\n",
    "\n",
    "    def _preprocess_image(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "        clahe = cv.createCLAHE(clipLimit=80, tileGridSize=(16, 16))\n",
    "        image = clahe.apply(image)\n",
    "        \n",
    "        image1 = image - np.min(image)\n",
    "        image = image1 / np.max(image1)\n",
    "        \n",
    "        # agumentation\n",
    "        if self.transform :\n",
    "            image = _random_augment(image)\n",
    "            \n",
    "        return image\n",
    "            \n",
    "    def _load_hdf5(self, hdf5_path):\n",
    "        with h5py.File(hdf5_path, 'r') as hf:  # open a hdf5 file\n",
    "            keys = list(hf.keys())\n",
    "            keys.sort()                   # sort key(image, input)\n",
    "\n",
    "            for fName in keys:\n",
    "                context = hf[fName]\n",
    "\n",
    "                if fName == 'input':\n",
    "                    image = np.array(hf.get(context.name))\n",
    "                elif fName == 'class_id':\n",
    "                    class_id = np.array(hf.get(context.name))[0]-1\n",
    "                    \n",
    "        hf.close()\n",
    "        \n",
    "        return image, class_id\n",
    "                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mode):\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = InfantDataset(transform=True, image_size=image_size, mode=mode)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2) \n",
    "    elif mode == 'val' or mode == 'test' :\n",
    "        dataset = InfantDataset(transform=False, image_size=image_size, mode=mode)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2) \n",
    "\n",
    "    return dataset, loader\n",
    "\n",
    "# pytorch Dataloader\n",
    "train_dataset, train_loader = get_data('train')\n",
    "val_dataset, val_loader = get_data('val')\n",
    "test_dataset, test_loader = get_data('test')\n",
    "\n",
    "\n",
    "data = train_dataset.__getitem__(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_train = len(train_dataset) \n",
    "num_data_val = len(val_dataset)  \n",
    "num_data_test = len(test_dataset)  \n",
    "\n",
    "num_batch_train = np.ceil(num_data_train / batch_size) \n",
    "num_batch_val = np.ceil(num_data_val / batch_size)\n",
    "num_batch_test = np.ceil(num_data_test / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.unet.model import Unet\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.vgg19(pretrained=True).to('cuda')\n",
    "# model = model.features\n",
    "# model_name = 'vgg_cnn'\n",
    "\n",
    "# classifier = nn.Sequential(OrderedDict([\n",
    "#                                 ('conv1', nn.Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).to('cuda')),\n",
    "#                                 ('relu', nn.ReLU()),\n",
    "#                                 ('conv2', nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).to('cuda')),\n",
    "#                                 ('relu', nn.ReLU()),\n",
    "#                                 ('bn', nn.BatchNorm2d(128)),\n",
    "#                                 ('maxpool', nn.MaxPool2d(kernel_size=3)),\n",
    "#                                 ('drop-out1', nn.Dropout(p=0.2, inplace=True)),\n",
    "#                                 ('flatten', nn.Flatten()),\n",
    "#                                 ('fc1', nn.Linear(512, 512)), \n",
    "#                                 ('drop-out2', nn.Dropout(p=0.2, inplace=True)),\n",
    "#                                 ('fc2', nn.Linear(512, 7)), \n",
    "#                             ]))\n",
    "\n",
    "# # model.classifier = classifier.to('cuda')\n",
    "# model[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.resnet18(pretrained=True).to('cuda')\n",
    "\n",
    "# model = torch.nn.Sequential(*(list(model.children())[:-2]))\n",
    "\n",
    "# model_name = 'res18_cnn'\n",
    "\n",
    "# classifier = nn.Sequential(OrderedDict([\n",
    "#                                 ('conv1', nn.Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).to('cuda')),\n",
    "#                                 ('relu', nn.ReLU()),\n",
    "#                                 ('conv2', nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).to('cuda')),\n",
    "#                                 ('relu', nn.ReLU()),\n",
    "#                                 ('bn', nn.BatchNorm2d(128)),\n",
    "#                                 ('maxpool', nn.MaxPool2d(kernel_size=3)),\n",
    "#                                 ('drop-out1', nn.Dropout(p=0.2, inplace=True)),\n",
    "#                                 ('flatten', nn.Flatten()),\n",
    "#                                 ('fc1', nn.Linear(512, 512)), \n",
    "#                                 ('drop-out2', nn.Dropout(p=0.2, inplace=True)),\n",
    "#                                 ('fc2', nn.Linear(512, 7)), \n",
    "#                             ]))\n",
    "\n",
    "# model.classifier = classifier.to('cuda')\n",
    "# model[0] = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)).to('cuda')\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True).to(device)\n",
    "model_name = 'resnet18'\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "fc = nn.Sequential(OrderedDict([\n",
    "                                ('fc1', nn.Linear(num_ftrs,100)),\n",
    "                                ('relu', nn.ReLU()),\n",
    "                                ('drop-out', nn.Dropout(p=0.2, inplace=True)),\n",
    "                                ('fc2', nn.Linear(100, num_class)),  # 3 is the number of classes we have in the dataset\n",
    "                            ]))\n",
    "model.fc = fc.to(device)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lr=0.00006\n",
    "lr = 1e-5\n",
    "momentum = 0.9\n",
    "num_epoch=500\n",
    "\n",
    "train_continue = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr= lr)  \n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "print(f'lr: {lr}, optim:{optimizer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model, mode='test'):\n",
    "    dict_model = torch.load(path)\n",
    "    print(\"Get saved weights successfully.\")\n",
    "    if mode == 'test':\n",
    "        return dict_model\n",
    "    else:\n",
    "        epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
    "        return model, epoch\n",
    "\n",
    "def save_model(ckpt_dir, model, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    if 'best' in ckpt_dir:\n",
    "        torch.save({'model': model.state_dict(), 'optim': optim.state_dict()},\n",
    "            \"./%s/model_best.pth\" % (ckpt_dir))\n",
    "        print(f'>> save model_best.pth')\n",
    "    else:\n",
    "        torch.save({'model': model.state_dict(), 'optim': optim.state_dict()},\n",
    "                    \"./%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n",
    "        print(f'>> save model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import ttach as tta\n",
    "\n",
    "transforms = tta.Compose([           \n",
    "    tta.Multiply(factors=[0.7, 1]),\n",
    "\n",
    "])\n",
    "\n",
    "def compute_metrics(model, test_loader, plot_roc_curve = False, mode='val'):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    losses = []\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    score_list   = torch.Tensor([]).to(device)\n",
    "    pred_list    = torch.Tensor([]).to(device).long()\n",
    "    target_list  = torch.Tensor([]).to(device).long()\n",
    "\n",
    "    tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "    \n",
    "    for iter_num, data in enumerate(test_loader):\n",
    "        \n",
    "        # Convert image data into single channel data\n",
    "        image, target = data['input'].to(device).float(), data['label'].to(device)\n",
    "        \n",
    "        if mode == 'val' :\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "        elif mode == 'test':\n",
    "            with torch.no_grad():\n",
    "                output = tta_model(image)\n",
    "        \n",
    "        # Log loss\n",
    "        val_loss += criterion(output, target.long()).item()\n",
    "        \n",
    "        # Calculate the number of correctly classified examples\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        pred_list    = torch.cat([pred_list, pred.squeeze()])\n",
    "        target_list  = torch.cat([target_list, target.squeeze()])\n",
    "    \n",
    "    classification_metrics = classification_report(target_list.tolist(), pred_list.tolist(),\n",
    "                                                  target_names = class_names,\n",
    "                                                  output_dict= True)\n",
    "\n",
    "    # sensitivity is the recall of the positive class\n",
    "    sensitivity = 0\n",
    "    for name in class_names:\n",
    "        sensitivity += classification_metrics[f'{name}']['recall']\n",
    "        \n",
    "    # specificity is the recall of the negative class \n",
    "    specificity = 0\n",
    "    for name in class_names:\n",
    "        specificity += classification_metrics[f'{name}']['precision']\n",
    "        \n",
    "    # accuracy\n",
    "    accuracy = classification_metrics['accuracy']\n",
    "    \n",
    "    \n",
    "    f1_score = 2 * (specificity * sensitivity) / (specificity + sensitivity)\n",
    "    \n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_list.tolist(), pred_list.tolist())\n",
    "    \n",
    "    # put together values\n",
    "    metrics_dict = {\"Accuracy\": accuracy * 100,\n",
    "                    \"Sensitivity\": (sensitivity * 100) / num_class,\n",
    "                    \"Specificity\": (specificity * 100) / num_class,\n",
    "                    \"F1 Score\": (f1_score * 100) / num_class,\n",
    "                    \"Validation Loss\": val_loss / len(test_loader),\n",
    "                    \"Confusion Matrix\": conf_matrix,\n",
    "                    \"pred_list\": pred_list.tolist(),\n",
    "                    \"target_list\": target_list.tolist(),}\n",
    "    \n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience = 8):\n",
    "        super(EarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.previous_loss = int(1e8)\n",
    "        self.previous_accuracy = 0\n",
    "        self.init = False\n",
    "        self.accuracy_decrease_iters = 0\n",
    "        self.loss_increase_iters = 0\n",
    "        self.best_running_accuracy = 0\n",
    "        self.best_running_loss = int(1e7)\n",
    "    \n",
    "    def add_data(self, model, loss, accuracy):\n",
    "        \n",
    "        # compute moving average\n",
    "        if not self.init:\n",
    "            running_loss = loss\n",
    "            running_accuracy = accuracy \n",
    "            self.init = True\n",
    "        \n",
    "        else:\n",
    "            running_loss = 0.2 * loss + 0.8 * self.previous_loss\n",
    "            running_accuracy = 0.2 * accuracy + 0.8 * self.previous_accuracy\n",
    "        \n",
    "        # check if running accuracy has improved beyond the best running accuracy recorded so far\n",
    "        if running_accuracy < self.best_running_accuracy:\n",
    "            self.accuracy_decrease_iters += 1\n",
    "        else:\n",
    "            self.best_running_accuracy = running_accuracy\n",
    "            self.accuracy_decrease_iters = 0\n",
    "        \n",
    "        # check if the running loss has decreased from the best running loss recorded so far\n",
    "        if running_loss > self.best_running_loss:\n",
    "            self.loss_increase_iters += 1\n",
    "        else:\n",
    "            self.best_running_loss = running_loss\n",
    "            self.loss_increase_iters = 0\n",
    "        \n",
    "        # log the current accuracy and loss\n",
    "        self.previous_accuracy = running_accuracy\n",
    "        self.previous_loss = running_loss        \n",
    "        \n",
    "    \n",
    "    def stop(self):\n",
    "        \n",
    "        # compute thresholds\n",
    "        accuracy_threshold = self.accuracy_decrease_iters > self.patience\n",
    "        loss_threshold = self.loss_increase_iters > self.patience\n",
    "        \n",
    "        \n",
    "        # return codes corresponding to exhuaustion of patience for either accuracy or loss \n",
    "        # or both of them\n",
    "        if accuracy_threshold and loss_threshold:\n",
    "            return 1\n",
    "        \n",
    "        if accuracy_threshold:\n",
    "            return 2\n",
    "        \n",
    "        if loss_threshold:\n",
    "            return 3\n",
    "        \n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def reset(self):\n",
    "        # reset\n",
    "        self.accuracy_decrease_iters = 0\n",
    "        self.loss_increase_iters = 0\n",
    "    \n",
    "early_stopper = EarlyStopping(patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=f'pulmonary-classification-{model_name}', reinit=True)\n",
    "wandb.run.name = 'v1'\n",
    "wandb.config = {'learning_rate':lr, 'epochs':num_epoch, 'batch_size':batch_size}\n",
    "wandb.watch(model)\n",
    "\n",
    "best_model = model\n",
    "best_val_score = 0\n",
    "\n",
    "st_epoch = 0\n",
    "for epoch in range(st_epoch + 1, num_epoch + 1):\n",
    "\n",
    "    model.train()    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for iter_num, data in enumerate(tqdm(train_loader), 1):\n",
    "        image = data['input'].to(device)       # [N, 3, image_size, image_size]\n",
    "        target = data['label'].to(device)        # [N, image_size, image_size]\n",
    "        \n",
    "        # Compute the loss\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target.long())\n",
    "        \n",
    "        # Log loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "        # Calculate the number of correctly classified examples\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "        \n",
    "    # Compute and print the performance metrics\n",
    "    metrics_dict = compute_metrics(model, val_loader)\n",
    "\n",
    "    # Save the model with best validation accuracy\n",
    "    if metrics_dict['F1 Score'] > best_val_score:\n",
    "        torch.save(model, f\"./checkpoint/best/best_model-{model_name}.pt\")\n",
    "        best_val_score = metrics_dict['F1 Score']\n",
    "        print('save best model')\n",
    "        \n",
    "#     if epoch  == 10:\n",
    "#         for param in model.parameters():\n",
    "#             param.requires_grad = True\n",
    "        \n",
    "\n",
    "    # print the metrics for training data for the epoch\n",
    "    print('Training Performance Epoch {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        epoch, train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    epoch_loss = train_loss/len(train_loader.dataset)\n",
    "    epoch_acc = 100.0 * train_correct / len(train_loader.dataset)\n",
    "    wandb.log({\"train-loss\": epoch_loss, \"train-acc\": epoch_acc, })\n",
    "    \n",
    "    \n",
    "    print(f\"Validation Performance Epoch: {epoch}, Loss: {metrics_dict['Validation Loss']}, Accuracy: {metrics_dict['Accuracy']}, F1 Score: {metrics_dict['F1 Score']}\")\n",
    "    \n",
    "    wandb.log({\"val-loss\": metrics_dict[\"Validation Loss\"],\n",
    "               \"val-acc\":metrics_dict[\"Accuracy\"],\n",
    "               \"val-sensitivity\": metrics_dict[\"Sensitivity\"],\n",
    "               \"val-specificity\": metrics_dict[\"Specificity\"],\n",
    "               \"val_f1-score\":  metrics_dict[\"F1 Score\"],\n",
    "              })\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        save_model(ckpt_dir='./checkpoint/log', model=model, optim=optimizer, epoch=epoch)\n",
    "    \n",
    "#     Add data to the EarlyStopper object\n",
    "    early_stopper.add_data(model, metrics_dict['Validation Loss'], metrics_dict['F1 Score'])\n",
    "\n",
    "    # If both accuracy and loss are not improving, stop the training\n",
    "    if early_stopper.stop() == 1:\n",
    "        break\n",
    "\n",
    "    # if only loss is not improving, lower the learning rate\n",
    "    if early_stopper.stop() == 3:\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr *= 0.1\n",
    "            param_group['lr'] = lr\n",
    "            print('Updating the learning rate to {}'.format(lr))\n",
    "            early_stopper.reset()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'./checkpoint/best/best_model-{model_name}.pt', model)\n",
    "    \n",
    "metrics_dict = compute_metrics(model, test_loader)\n",
    "print('------------------- Test Performance --------------------------------------')\n",
    "print(\"Accuracy \\t {:.3f}\".format(metrics_dict['Accuracy']))\n",
    "print(\"Sensitivity \\t {:.3f}\".format(metrics_dict['Sensitivity']))\n",
    "print(\"Specificity \\t {:.3f}\".format(metrics_dict['Specificity']))\n",
    "print(\"F1 Score \\t {:.3f}\".format(metrics_dict['F1 Score']))\n",
    "print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
